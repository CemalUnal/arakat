### APP SPECIFIC ###
server.servlet.context-path=/arakat-java-service/
server.port=8084

### MONGODB SPECIFIC ###
spring.data.mongodb.database=arakat
spring.data.mongodb.host=localhost
spring.data.mongodb.port=27017

### JSON FILE LOCATIONS ###
#json.config.folder=/home/astar/astar/forked-git-repos/arakat/arakat/arakat-backend/configs/cemal
json.config.folder=/home/astar/astar/forked-git-repos/arakat/arakat-core/configs/node_specs

### LOCATIONS TO SAVE PYTHON & DAG OUTPUT FILES ###
dag.output.file.location=/airflow_dag/
spark.codes.output.file.location=/spark_codes/

### CONFIGS FOR THE GRAPH ###
#todo: remove these
bash.command=sh\u0020/usr/local/shell_scripts/run.sh

### ARAKAT CORE SPECIFIC ###
arakat.core.url=http://localhost
#arakat.core.url=http://10.154.3.18
arakat.core.port=5001
#arakat.core.port=5000
arakat.core.posting.graph.endpoint=interpret_graph

### AIRFLOW SPECIFIC ###
airflow.url=http://10.154.3.14
airflow.port=8080
airflow.dag.status.path=/admin/airflow/dag_stats
airflow.task.status.path=/admin/airflow/task_stats
airflow.dag.logs.file.path=/airflow_logs/

### SPARK AND HADOOP SPECIFIC ###
spark.logs.file.path=/spark_logs/

### HDFS READER ###
hdfs.reader.url=http://10.154.3.17
hdfs.reader.port=5001
hdfs.reader.get.table.columns.endpoint=get-table-columns
hdfs.reader.get.table.columns.with.types.endpoint=get-table-columns-with-types
hdfs.reader.get.data.endpoint=get-data
