{
"name": "csv",
"id": 52,
"category": 0,
"family": 10,
"incompatible_families": [11,12,13],
"requires_udf": false,
"is_splitter": false,
"compatible_with_spark_pipeline": false,
"compatible_with_stream": false,
"compatible_stream_output_modes": [],
"produces_model": false,
"parameter_props": {"path": {"type": ["string"], "constraints":[], "default":"None"},"schema": {"type": ["StructType"], "constraints":[], "default":"None"},"header": {"type": ["bool"], "constraints":[], "default":"False"},"inferSchema": {"type": ["bool"], "constraints":[], "default":"False"},"sep": {"type": ["char"], "constraints":[], "default":","},"quote": {"type": ["char"], "constraints":[], "default":"\""}},
"df_constraints": [],
"import": "from pyspark.sql import SparkSession",
"explanation": "Path: valid data path. InferSchema: infers the input schema automatically from data. Header: uses the first line as names of columns. Sep: sets a single character as a separator for each field and value. Quote: sets a single character used for escaping quoted values where the separator can be part of the value."
}
