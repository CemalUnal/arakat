{
"name": "RandomSplitNode",
"id": 49,
"category": 2,
"family": 8,
"incompatible_families": [10,11,12,13],
"requires_udf": false,
"is_splitter": true,
"compatible_with_spark_pipeline": false,
"compatible_with_stream": false,
"compatible_stream_output_modes": [],
"produces_model": false,
"parameter_props": {"weights": {"type": ["double array"], "constraints":[], "default":"None"},"seed": {"type": ["int"], "constraints":[], "default":"None"}},
"df_constraints": [14],
"import": "from pyspark.sql import SparkSession",
"explanation": "Splits dataframe. Weights: list of doubles as weights with which to split the DataFrame. Weights will be normalized if they donâ€™t sum up to 1.0."
}
